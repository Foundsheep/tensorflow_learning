{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Foundsheep/tensorflow_learning/blob/main/guide_03_autodiff.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Key takeaways\n",
        "--- \n",
        "- `tf.GradientTape()` API by default assumes to have `tf.Variable` variables and they are trainable. `tf.constant` or `tf.Variable` with `trainable=False` parameter are not to be recorded in the tape for gradient calculation\n",
        "- `tf.Variable()` + `tf.Tensor` returns `tf.Tensor`\n",
        "- `tape.watch()` could indicate a tensor that the user wants the tape to record, and it could be `tf.constant`\n",
        "- `tf.GradientTape(persistent=False)` -> if persistent parameter is set to `False`, it can only be used once to compute gradients\n",
        "- tape record holds many intermidiate values, so it could hold up a lot of memory(if `persistent=True` is set, the memory usage will be constantly high until it is manually discarded)\n",
        "- if the target(s) are not scalar the gradient of the sum is calculated\n",
        "- if a different variable is used on each branch of an `if`, the gradient only connects to the variable that was used\n",
        "- **several ways how gradient calculation could go wrong**"
      ],
      "metadata": {
        "id": "B88cF50sFU-s"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFdPvlXBOdUN"
      },
      "source": [
        "# Introduction to gradients and automatic differentiation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/autodiff\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/autodiff.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/autodiff.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/guide/autodiff.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6P32iYYV27b"
      },
      "source": [
        "## Automatic Differentiation and Gradients\n",
        "\n",
        "[Automatic differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation)\n",
        "is useful for implementing machine learning algorithms such as\n",
        "[backpropagation](https://en.wikipedia.org/wiki/Backpropagation) for training\n",
        "neural networks.\n",
        "\n",
        "In this guide, you will explore ways to compute gradients with TensorFlow, especially in eager execution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUXex9ctTuDB"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqR2PQG4ZaZ0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHxb-dlhMIzW"
      },
      "source": [
        "## Computing gradients\n",
        "\n",
        "To differentiate automatically, TensorFlow needs to remember what operations happen in what order during the *forward* pass.  Then, during the *backward pass*, TensorFlow traverses this list of operations in reverse order to compute gradients."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CLWJl0QliB0"
      },
      "source": [
        "## Gradient tapes\n",
        "\n",
        "TensorFlow provides the `tf.GradientTape` API for automatic differentiation; that is, computing the gradient of a computation with respect to some inputs, usually `tf.Variable`s.\n",
        "TensorFlow \"records\" relevant operations executed inside the context of a `tf.GradientTape` onto a \"tape\". TensorFlow then uses that tape to compute the gradients of a \"recorded\" computation using [reverse mode differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation).\n",
        "\n",
        "Here is a simple example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xq9GgTCP7a4A"
      },
      "outputs": [],
      "source": [
        "x = tf.Variable(3.0)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  y = x**2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### exploration\n",
        "---\n",
        "---\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "w8wYj3v3HOzx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "id": "9m3GvvxCHNhz",
        "outputId": "15421c42-b730-40b2-9b63-b4c5d4f1348e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=3.0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tape"
      ],
      "metadata": {
        "id": "ZFpT9V5IHTED",
        "outputId": "16b1c480-bbfe-414a-cc80-48ec8d979a93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.eager.backprop.GradientTape at 0x7f66d3783810>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "kAQHGcn6HWxo",
        "outputId": "5f285aff-9dad-4a34-831c-697349e03822",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=9.0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "caOVeQq9HbR_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CR9tFAP_7cra"
      },
      "source": [
        "Once you've recorded some operations, use `GradientTape.gradient(target, sources)` to calculate the gradient of some target (often a loss) relative to some source (often the model's variables):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LsvrwF6bHroC",
        "outputId": "d1a2f36d-29fc-4a2b-da3e-37ef9f723858",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.0"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# dy = 2x * dx\n",
        "dy_dx = tape.gradient(y, x)\n",
        "dy_dx.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### exploration\n",
        "---\n",
        "---\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "Jk6JoQT_H8mN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dy_dx"
      ],
      "metadata": {
        "id": "Emuu55l6HpIO",
        "outputId": "217897c5-184d-4ff7-d7ba-e8275f70497a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=6.0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    tape.gradient(y, 2)\n",
        "except Exception as e:\n",
        "    print(type(e))\n",
        "    print()\n",
        "    print((e))"
      ],
      "metadata": {
        "id": "-xrSEn2MIFN1",
        "outputId": "2522b944-ba42-4a05-a133-4be9fded4adc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'RuntimeError'>\n",
            "\n",
            "A non-persistent GradientTape can only be used to compute one set of gradients (or jacobians)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "Fsn6THu9IAK2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2_aqsO25Vx1"
      },
      "source": [
        "The above example uses scalars, but `tf.GradientTape` works as easily on any tensor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vacZ3-Ws5VdV"
      },
      "outputs": [],
      "source": [
        "# w = tf.Variable(tf.random.normal((3, 2)), name='w')\n",
        "# b = tf.Variable(tf.zeros(2, dtype=tf.float32), name='b')\n",
        "# x = [[1., 2., 3.]]\n",
        "\n",
        "# with tf.GradientTape(persistent=True) as tape:\n",
        "#   y = x @ w + b\n",
        "#   loss = tf.reduce_mean(y**2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### exploration\n",
        "---\n",
        "---\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "PtwRjrkwKL0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.normal((3, 2))"
      ],
      "metadata": {
        "id": "9MYIGbW8JJUJ",
        "outputId": "7f3c9717-e8f8-4244-b56b-724b2c13ceae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
              "array([[-1.2158865 , -0.44141278],\n",
              "       [ 0.29698724,  0.59972507],\n",
              "       [-0.43439364,  1.3470625 ]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.Variable(tf.random.normal((3, 2)), name='temp_w')"
      ],
      "metadata": {
        "id": "n9rRUJBTJTJ4",
        "outputId": "c5dd5d33-9628-43bd-b885-4b34706b0532",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'temp_w:0' shape=(3, 2) dtype=float32, numpy=\n",
              "array([[ 0.3798453 ,  1.4294944 ],\n",
              "       [-0.40006116, -0.08656219],\n",
              "       [ 0.4767466 ,  0.97510505]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.constant([[1., 2., 3.]]).shape"
      ],
      "metadata": {
        "id": "LoyWfhmiJtwX",
        "outputId": "ad02c363-ee56-4f9c-e717-d475164fcfe9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = tf.Variable(tf.random.normal((3, 2)), name='w')\n",
        "b = tf.Variable(tf.zeros(2, dtype=tf.float32), name='b')\n",
        "x = [[1., 2., 3.]]\n",
        "\n",
        "with tf.GradientTape(persistent=True) as tape:\n",
        "    y = x @ w + b\n",
        "    loss = tf.reduce_mean(y**2)"
      ],
      "metadata": {
        "id": "FEPmiO2tJZ-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss"
      ],
      "metadata": {
        "id": "J7AxN408KK9w",
        "outputId": "47370d0d-7173-4713-804b-5b216c6bde89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=13.052082>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "EJbeWrylKU3G",
        "outputId": "d46c38e3-8cbb-4fc2-ecd0-5124a49670ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[ 5.097055  , -0.35241452]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y**2"
      ],
      "metadata": {
        "id": "FqnMkFH4KaBD",
        "outputId": "bcf812a5-53c0-432f-cbfc-ea1a1708bd07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[25.979969  ,  0.12419599]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "43CcDeQlKb67"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4eXOkrQ-9Pb"
      },
      "source": [
        "To get the gradient of `loss` with respect to both variables, you can pass both as sources to the `gradient` method. The tape is flexible about how sources are passed and will accept any nested combination of lists or dictionaries and return the gradient structured the same way (see `tf.nest`)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[dl_dw, dl_db] = tape.gradient(loss, [w, b])"
      ],
      "metadata": {
        "id": "jvxapBcZKlyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### exploration\n",
        "---\n",
        "---\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "IQ2s7lY4LviP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dl_dw"
      ],
      "metadata": {
        "id": "5Wz3KcPpKsDy",
        "outputId": "592baf6f-3ecb-409a-cf26-19ee2ed40b64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
              "array([[ 5.097055  , -0.35241452],\n",
              "       [10.19411   , -0.70482904],\n",
              "       [15.291164  , -1.0572436 ]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dl_db"
      ],
      "metadata": {
        "id": "0D3EsbhPLDvR",
        "outputId": "97d3caab-a006-417b-9dcb-2921bf288ffd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([ 5.097055  , -0.35241452], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> - `gradient`에 대해 생각해보자.\n",
        "> - 지금 gradient를 구한 것을 보면, `w`, `b`로 각각의 값들이 정해진 상태이다.\n",
        "> - 그리고 그 값들이 정해졌을 때 나온 `loss`값이 있는데, `w`, `b`이 정해진 상태이기 때문에 도함수라기 보다 도함수에 w, b 값들이 각각 들어가서 `loss`에 대한 각각 현재 위치에 있는 점들의 `기울기`, 즉 변화율을 구한 것이다."
      ],
      "metadata": {
        "id": "DgwPYqBULLUK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "VvZCBsPBLsYg"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ei4iVXi6qgM7"
      },
      "source": [
        "The gradient with respect to each source has the shape of the source:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYbWRFPZqk4U",
        "outputId": "89f2386c-5aef-4e6e-cc8c-a79eaec7886a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 2)\n",
            "(3, 2)\n"
          ]
        }
      ],
      "source": [
        "print(w.shape)\n",
        "print(dl_dw.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dI_SzxHsvao1"
      },
      "source": [
        "Here is the gradient calculation again, this time passing a dictionary of variables:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_var = {\n",
        "    'w': w,\n",
        "    'b': b,\n",
        "}\n",
        "\n",
        "grad = tape.gradient(loss, my_var)\n",
        "grad['b']"
      ],
      "metadata": {
        "id": "sBEgVZdUL63-",
        "outputId": "69c3aea5-501b-4c23-b0a6-ce0c4c6fcba2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([ 5.097055  , -0.35241452], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### exploration\n",
        "---\n",
        "---\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "E_PQBODlMp0z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grad"
      ],
      "metadata": {
        "id": "uYjk1UfyMjKj",
        "outputId": "3dd30b0d-b323-4b3a-f20e-00f8428305a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'b': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([ 5.097055  , -0.35241452], dtype=float32)>,\n",
              " 'w': <tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
              " array([[ 5.097055  , -0.35241452],\n",
              "        [10.19411   , -0.70482904],\n",
              "        [15.291164  , -1.0572436 ]], dtype=float32)>}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(grad)"
      ],
      "metadata": {
        "id": "T2CBhHrKMmDy",
        "outputId": "f36e75b6-e88c-4c87-e6d7-25ab8a39eb2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tape.gradient(loss, w)"
      ],
      "metadata": {
        "id": "qkQNelqqMzZ6",
        "outputId": "ff8ade7d-03bd-4635-9693-b461181aa1c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
              "array([[ 5.097055  , -0.35241452],\n",
              "       [10.19411   , -0.70482904],\n",
              "       [15.291164  , -1.0572436 ]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w[0]"
      ],
      "metadata": {
        "id": "IWNljJFANClC",
        "outputId": "e381fb5a-2c23-4997-dbb6-a57f0e6bdd73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([-1.0367007,  1.6459978], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(tape.gradient(loss, w[0]))"
      ],
      "metadata": {
        "id": "umGRF5taM1uK",
        "outputId": "232b8a07-37f9-49ba-f67c-b6f404299242",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NoneType"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tape.gradient(loss, b)"
      ],
      "metadata": {
        "id": "YQ7WFysnNG-8",
        "outputId": "f6f64a10-c76c-44ca-cc71-09e8a4d7352e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([ 5.097055  , -0.35241452], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(tape.gradient(loss, b[0]))"
      ],
      "metadata": {
        "id": "lVMeizDxNJO5",
        "outputId": "f28a6bda-32ff-45bd-e1b3-6148a01a13bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NoneType"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> - gradient source로 넣는 것을 보니까 operation에 있었던 모든 수에 대해서 gradient를 구해주는 게 아니라, operation 되었던 그 형태 그대로 source로 주어져야 하는 것 같다."
      ],
      "metadata": {
        "id": "6QupfHQPNOYw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "hmErpFnGMnjL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZ2LvHifEMgO"
      },
      "source": [
        "## Gradients with respect to a model\n",
        "\n",
        "It's common to collect `tf.Variables` into a `tf.Module` or one of its subclasses (`layers.Layer`, `keras.Model`) for [checkpointing](checkpoint.ipynb) and [exporting](saved_model.ipynb).\n",
        "\n",
        "In most cases, you will want to calculate gradients with respect to a model's trainable variables.  Since all subclasses of `tf.Module` aggregate their variables in the `Module.trainable_variables` property, you can calculate these gradients in a few lines of code: "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QnNs5A8nOC-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer = tf.keras.layers.Dense(2, activation='relu')\n",
        "x = tf.constant([[1., 2., 3.]])\n",
        "\n",
        "dj_x = tf.constant([1., 2., 3.]) # dj added for practice\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    # Forward pass\n",
        "    y = layer(x)\n",
        "    loss = tf.reduce_mean(y**2)\n",
        "\n",
        "    # Calculate gradients with respect to every trainable variable\n",
        "    grad = tape.gradient(loss, layer.trainable_variables)"
      ],
      "metadata": {
        "id": "yuQFjIWiODAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### exploration\n",
        "---\n",
        "---\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "IXzXbbGsTIPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 추가로 해본 것\n",
        "try:\n",
        "    with tf.GradientTape() as dj_tape:\n",
        "        # Forward pass\n",
        "        dj_y = layer(dj_x)\n",
        "\n",
        "        dj_loss = tf.reduce_mean(dj_y**2)\n",
        "\n",
        "        # Calculate gradients with respect to every trainable variable\n",
        "        grad = tape.gradient(loss, layer.trainable_variables)\n",
        "except Exception as e:\n",
        "    print(f\"{type(e).__name__} : {e}\")"
      ],
      "metadata": {
        "id": "LMS2H8PqOoT2",
        "outputId": "968d3f90-d49b-475c-a5a9-e3fe30cb08d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ValueError : Input 0 of layer \"dense\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (3,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for var, g in zip(layer.trainable_variables, grad):\n",
        "    print(f'{var.name}, shape: {g.shape}')"
      ],
      "metadata": {
        "id": "5tiI-WTHSOy7",
        "outputId": "1f1e8c37-d716-404c-92d6-bd9bd580cc91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dense/kernel:0, shape: (3, 2)\n",
            "dense/bias:0, shape: (2,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layer.trainable_variables"
      ],
      "metadata": {
        "id": "NPYwRhRrSc0B",
        "outputId": "cdfbe673-3063-4a80-e53b-bc72fca56ebb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'dense/kernel:0' shape=(3, 2) dtype=float32, numpy=\n",
              " array([[ 0.02088583,  0.05375576],\n",
              "        [-1.0784519 ,  1.0753014 ],\n",
              "        [-0.77314776,  0.8821502 ]], dtype=float32)>,\n",
              " <tf.Variable 'dense/bias:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grad"
      ],
      "metadata": {
        "id": "2Q44019GS253",
        "outputId": "b92106b7-0227-42ee-a7d9-4c70c65295fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
              " array([[ 0.      ,  4.850809],\n",
              "        [ 0.      ,  9.701618],\n",
              "        [ 0.      , 14.552427]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.      , 4.850809], dtype=float32)>]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "pzgM7BTkS--m"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6Gx6LS714zR"
      },
      "source": [
        "<a id=\"watches\"></a>\n",
        "\n",
        "## Controlling what the tape watches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4VlqKFzzGaC"
      },
      "source": [
        "The default behavior is to record all operations after accessing a trainable `tf.Variable`. The reasons for this are:\n",
        "\n",
        "* The tape needs to know which operations to record in the forward pass to calculate the gradients in the backwards pass.\n",
        "* The tape holds references to intermediate outputs, so you don't want to record unnecessary operations.\n",
        "* The most common use case involves calculating the gradient of a loss with respect to all a model's trainable variables.\n",
        "\n",
        "For example, the following fails to calculate a gradient because the `tf.Tensor` is not \"watched\" by default, and the `tf.Variable` is not trainable:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kj9gPckdB37a",
        "outputId": "80aefcdf-94d8-4b09-ce09-40504c5c1eb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(6.0, shape=(), dtype=float32)\n",
            "None\n",
            "None\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# A trainable variable\n",
        "x0 = tf.Variable(3.0, name='x0')\n",
        "# Not trainable\n",
        "x1 = tf.Variable(3.0, name='x1', trainable=False)\n",
        "# Not a Variable: A variable + tensor returns a tensor.\n",
        "x2 = tf.Variable(2.0, name='x2') + 1.0\n",
        "# Not a variable\n",
        "x3 = tf.constant(3.0, name='x3')\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  y = (x0**2) + (x1**2) + (x2**2)\n",
        "\n",
        "grad = tape.gradient(y, [x0, x1, x2, x3])\n",
        "\n",
        "for g in grad:\n",
        "  print(g)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkcpQnLgNxgi"
      },
      "source": [
        "You can list the variables being watched by the tape using the `GradientTape.watched_variables` method:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[var.name for var in tape.watched_variables()]"
      ],
      "metadata": {
        "id": "YV4aAjZlU1vB",
        "outputId": "ab3c6501-e34c-4200-f78b-207107d3d9a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['x0:0']"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NB9I1uFvB4tf"
      },
      "source": [
        "`tf.GradientTape` provides hooks that give the user control over what is or is not watched.\n",
        "\n",
        "To record gradients with respect to a `tf.Tensor`, you need to call `GradientTape.watch(x)`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVN1QqFRDHBK",
        "outputId": "f19aecbe-3a37-416b-996f-7a81a32f2fc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6.0\n"
          ]
        }
      ],
      "source": [
        "x = tf.constant(3.0)\n",
        "with tf.GradientTape() as tape:\n",
        "  tape.watch(x)\n",
        "  y = x**2\n",
        "\n",
        "# dy = 2x * dx\n",
        "dy_dx = tape.gradient(y, x)\n",
        "print(dy_dx.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### exploration\n",
        "---\n",
        "---\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "1uBbtfz1VbGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dy_dx"
      ],
      "metadata": {
        "id": "TMlgEIhhVVjr",
        "outputId": "80db0d65-e2aa-4cd3-a34a-44044556a9a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=6.0>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "cjSjtNR2VXKM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxsiYnf2DN8K"
      },
      "source": [
        "Conversely, to disable the default behavior of watching all `tf.Variables`, set `watch_accessed_variables=False` when creating the gradient tape. This calculation uses two variables, but only connects the gradient for one of the variables:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QPzwWvSEwIp"
      },
      "outputs": [],
      "source": [
        "x0 = tf.Variable(0.0)\n",
        "x1 = tf.Variable(10.0)\n",
        "\n",
        "with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
        "  tape.watch(x1)\n",
        "  y0 = tf.math.sin(x0)\n",
        "  y1 = tf.nn.softplus(x1)\n",
        "  y = y0 + y1\n",
        "  ys = tf.reduce_sum(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### exploration\n",
        "---\n",
        "---\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "TO1PgmE0YMvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tape.gradient(ys, [x0, x1])"
      ],
      "metadata": {
        "id": "envCskfwWYpd",
        "outputId": "fe100545-c550-4b49-b338-2e3825767fed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, <tf.Tensor: shape=(), dtype=float32, numpy=0.9999546>]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    tape.gradient(y0, x0)\n",
        "except Exception as e:\n",
        "    print(f\"{type(e).__name__} : {e}\")\n"
      ],
      "metadata": {
        "id": "nKGkc1trWi6m",
        "outputId": "1fcac6b7-89b6-4331-b57f-cb1f8b708a7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RuntimeError : A non-persistent GradientTape can only be used to compute one set of gradients (or jacobians)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> - `tape.gradient()`의 타겟은 최종 출력값이고, 소스는 첫 입력값들이어야 하나...?\n",
        "> - 보니까 오류가 나는 이유는 그것 때문이 아니라, 저 tape의 persistent 파라미터가 `False`로 지정되어 있는데, 그러면 한 번만 gradient를 구할 수 있단다."
      ],
      "metadata": {
        "id": "YErg19Z2XEny"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "X0f_vhFWYS70"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRduLbE1H2IJ"
      },
      "source": [
        "Since `GradientTape.watch` was not called on `x0`, no gradient is computed with respect to it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6GM-3evH1Sz",
        "outputId": "a533c4ee-80f4-425e-ccc4-efe95821322f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dy/dx0: None\n",
            "dy/dx1: 0.9999546\n"
          ]
        }
      ],
      "source": [
        "# dys/dx1 = exp(x1) / (1 + exp(x1)) = sigmoid(x1)\n",
        "grad = tape.gradient(ys, {'x0': x0, 'x1': x1})\n",
        "\n",
        "print('dy/dx0:', grad['x0'])\n",
        "print('dy/dx1:', grad['x1'].numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2g1nKB6P-OnA"
      },
      "source": [
        "## Intermediate results\n",
        "\n",
        "You can also request gradients of the output with respect to intermediate values computed inside the `tf.GradientTape` context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XaPRAwUyYms",
        "outputId": "e35340c5-694b-4f68-d6a8-3a195722d73e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18.0\n"
          ]
        }
      ],
      "source": [
        "x = tf.constant(3.0)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  tape.watch(x)\n",
        "  y = x * x\n",
        "  z = y * y\n",
        "\n",
        "# Use the tape to compute the gradient of z with respect to the\n",
        "# intermediate value y.\n",
        "# dz_dy = 2 * y and y = x ** 2 = 9\n",
        "print(tape.gradient(z, y).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISkXuY7YzIcS"
      },
      "source": [
        "By default, the resources held by a `GradientTape` are released as soon as the `GradientTape.gradient` method is called. To compute multiple gradients over the same computation, create a gradient tape with `persistent=True`. This allows multiple calls to the `gradient` method as resources are released when the tape object is garbage collected. For example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZaCm3-9zVCi",
        "outputId": "b81c002a-8638-46ad-922f-e919952d599e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  4. 108.]\n",
            "[2. 6.]\n"
          ]
        }
      ],
      "source": [
        "x = tf.constant([1, 3.0])\n",
        "with tf.GradientTape(persistent=True) as tape:\n",
        "  tape.watch(x)\n",
        "  y = x * x\n",
        "  z = y * y\n",
        "\n",
        "print(tape.gradient(z, x).numpy())  # [4.0, 108.0] (4 * x**3 at x = [1.0, 3.0])\n",
        "print(tape.gradient(y, x).numpy())  # [2.0, 6.0] (2 * x at x = [1.0, 3.0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8bv_jQFg6CN"
      },
      "outputs": [],
      "source": [
        "del tape   # Drop the reference to the tape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_ZY-9BUB7vX"
      },
      "source": [
        "## Notes on performance\n",
        "\n",
        "* There is a tiny overhead associated with doing operations inside a gradient tape context. For most eager execution this will not be a noticeable cost, but you should still use tape context around the areas only where it is required.\n",
        "\n",
        "* Gradient tapes use memory to store intermediate results, including inputs and outputs, for use during the backwards pass.\n",
        "\n",
        "  For efficiency, some ops (like `ReLU`) don't need to keep their intermediate results and they are pruned during the forward pass. However, if you use `persistent=True` on your tape, *nothing is discarded* and your peak memory usage will be higher."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dLBpZsJebFq"
      },
      "source": [
        "## Gradients of non-scalar targets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pldU9F5duP2"
      },
      "source": [
        "A gradient is fundamentally an operation on a scalar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qI0sDV_WeXBb",
        "outputId": "9b585cfb-7530-4223-b72a-08ad5d681ed8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.0\n",
            "-0.25\n"
          ]
        }
      ],
      "source": [
        "x = tf.Variable(2.0)\n",
        "with tf.GradientTape(persistent=True) as tape:\n",
        "  y0 = x**2\n",
        "  y1 = 1 / x\n",
        "\n",
        "print(tape.gradient(y0, x).numpy())\n",
        "print(tape.gradient(y1, x).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COEyYp34fxj4"
      },
      "source": [
        "Thus, if you ask for the gradient of multiple targets, the result for each source is:\n",
        "\n",
        "* The gradient of the sum of the targets, or equivalently\n",
        "* The sum of the gradients of each target."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4a6_YOcfWKS",
        "outputId": "53c6a84b-cd85-4269-e936-efcc016947fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.75\n"
          ]
        }
      ],
      "source": [
        "x = tf.Variable(2.0)\n",
        "with tf.GradientTape() as tape:\n",
        "  y0 = x**2\n",
        "  y1 = 1 / x\n",
        "\n",
        "print(tape.gradient({'y0': y0, 'y1': y1}, x).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvP-mkBMgbym"
      },
      "source": [
        "Similarly, if the target(s) are not scalar the gradient of the sum is calculated:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DArPWqsSh5un",
        "outputId": "a86a5c96-a0a5-4121-8632-da05c16cb818",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.0\n"
          ]
        }
      ],
      "source": [
        "x = tf.Variable(2.)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  y = x * [3., 4.]\n",
        "\n",
        "print(tape.gradient(y, x).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flDbx68Zh5Lb"
      },
      "source": [
        "This makes it simple to take the gradient of the sum of a collection of losses, or the gradient of the sum of an element-wise loss calculation.\n",
        "\n",
        "If you need a separate gradient for each item, refer to [Jacobians](advanced_autodiff.ipynb#jacobians)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwFswok8RAly"
      },
      "source": [
        "In some cases you can skip the Jacobian. For an element-wise calculation, the gradient of the sum gives the derivative of each element with respect to its input-element, since each element is independent:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQvk_jnMmTDS"
      },
      "outputs": [],
      "source": [
        "x = tf.linspace(-10.0, 10.0, 200+1)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  tape.watch(x)\n",
        "  y = tf.nn.sigmoid(x)\n",
        "\n",
        "dy_dx = tape.gradient(y, x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_f2QgDPmcPE",
        "outputId": "989165a7-4e84-4a48-9097-383f06969c25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(x, y, label='y')\n",
        "plt.plot(x, dy_dx, label='dy/dx')\n",
        "plt.legend()\n",
        "_ = plt.xlabel('x')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kADybtQzYj4"
      },
      "source": [
        "## Control flow\n",
        "\n",
        "Because a gradient tape records operations as they are executed, Python control flow is naturally handled (for example, `if` and `while` statements).\n",
        "\n",
        "Here a different variable is used on each branch of an `if`. The gradient only connects to the variable that was used:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ciFLizhrrjy7",
        "outputId": "727a87a3-cc38-490a-a7ab-8de0cf814077",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(1.0, shape=(), dtype=float32)\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "x = tf.constant(1.0)\n",
        "\n",
        "v0 = tf.Variable(2.0)\n",
        "v1 = tf.Variable(2.0)\n",
        "\n",
        "with tf.GradientTape(persistent=True) as tape:\n",
        "  tape.watch(x)\n",
        "  if x > 0.0:\n",
        "    result = v0\n",
        "  else:\n",
        "    result = v1**2 \n",
        "\n",
        "dv0, dv1 = tape.gradient(result, [v0, v1])\n",
        "\n",
        "print(dv0)\n",
        "print(dv1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKnLaiapsjeP"
      },
      "source": [
        "Just remember that the control statements themselves are not differentiable, so they are invisible to gradient-based optimizers.\n",
        "\n",
        "Depending on the value of `x` in the above example, the tape either records `result = v0` or `result = v1**2`. The gradient with respect to `x` is always `None`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8k05WmuAwPm7",
        "outputId": "d3a86c8d-da56-4f37-c901-b9773b9e7d89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "dx = tape.gradient(result, x)\n",
        "\n",
        "print(dx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egypBxISAHhx"
      },
      "source": [
        "## Getting a gradient of `None`\n",
        "\n",
        "When a target is not connected to a source you will get a gradient of `None`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CU185WDM81Ut",
        "outputId": "e7ee9af7-14cf-42ea-e0b7-181d8078f29d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "x = tf.Variable(2.)\n",
        "y = tf.Variable(3.)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  z = y * y\n",
        "print(tape.gradient(z, x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZbKpHfBRJym"
      },
      "source": [
        "Here `z` is obviously not connected to `x`, but there are several less-obvious ways that a gradient can be disconnected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHDzDOiQ8xmw"
      },
      "source": [
        "### 1. Replaced a variable with a tensor\n",
        "\n",
        "In the section on [\"controlling what the tape watches\"](#watches) you saw that the tape will automatically watch a `tf.Variable` but not a `tf.Tensor`.\n",
        "\n",
        "One common error is to inadvertently replace a `tf.Variable` with a `tf.Tensor`, instead of using `Variable.assign` to update the `tf.Variable`. Here is an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPKY4Tn9zX7_",
        "outputId": "3fb0bdbc-9ac4-4b98-e4c6-e18b44f4fe73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResourceVariable : tf.Tensor(1.0, shape=(), dtype=float32)\n",
            "EagerTensor : None\n"
          ]
        }
      ],
      "source": [
        "x = tf.Variable(2.0)\n",
        "\n",
        "for epoch in range(2):\n",
        "  with tf.GradientTape() as tape:\n",
        "    y = x+1\n",
        "\n",
        "  print(type(x).__name__, \":\", tape.gradient(y, x))\n",
        "  x = x + 1   # This should be `x.assign_add(1)`"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### exploration\n",
        "---\n",
        "---\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "SSyKf8izfQ45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "OyISHoAwfBD6",
        "outputId": "481526bf-af46-4007-829a-4a2ae5d0663a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=4.0>"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "id": "ia2IZoKwfCpR",
        "outputId": "6b4b2568-d414-4e73-be8c-075eadfb0823",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=4.0>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp_x = tf.Variable(2.0)\n",
        "temp_x.assign_add(1)"
      ],
      "metadata": {
        "id": "VqqXuIMefGKJ",
        "outputId": "79861107-e9e6-457b-b796-54e09f8bbc9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=3.0>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "tSqp-aDffN1x"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gwZKxgA97an"
      },
      "source": [
        "### 2. Did calculations outside of TensorFlow\n",
        "\n",
        "The tape can't record the gradient path if the calculation exits TensorFlow.\n",
        "For example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmoLCDJb_yw1",
        "outputId": "7fb7f818-6bcb-4b9f-bc63-b11d947429a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "x = tf.Variable([[1.0, 2.0],\n",
        "                 [3.0, 4.0]], dtype=tf.float32)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  x2 = x**2\n",
        "\n",
        "  # This step is calculated with NumPy\n",
        "  y = np.mean(x2, axis=0)\n",
        "\n",
        "  # Like most ops, reduce_mean will cast the NumPy array to a constant tensor\n",
        "  # using `tf.convert_to_tensor`.\n",
        "  y = tf.reduce_mean(y, axis=0)\n",
        "\n",
        "print(tape.gradient(y, x))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### exploration\n",
        "---\n",
        "---\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "zn4RpLG_g7mx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "id": "o1BEPclmgHt8",
        "outputId": "7e100e0d-366e-434b-c61b-6bf51e33b3d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
              "array([[1., 2.],\n",
              "       [3., 4.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x2"
      ],
      "metadata": {
        "id": "peJHJ1KtgKG8",
        "outputId": "895f0db4-9099-4132-d2ef-b66a4b842f9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              "array([[ 1.,  4.],\n",
              "       [ 9., 16.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(x2, axis=0)"
      ],
      "metadata": {
        "id": "ZArM7cJJgLw7",
        "outputId": "011ed905-ed59-4178-f2a9-b2e756c3f1d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 5., 10.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.reduce_mean(np.mean(x2, axis=0), axis=0)"
      ],
      "metadata": {
        "id": "B_-buBr9gSFT",
        "outputId": "943ba5e0-287b-4cb2-93e1-388f514809e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=7.5>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.convert_to_tensor(np.mean(x2, axis=0))"
      ],
      "metadata": {
        "id": "_FcOLUiygXgq",
        "outputId": "ee00b472-426b-4690-a529-dcc7216a50b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([ 5., 10.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.GradientTape() as tape:\n",
        "    x2 = x**2\n",
        "    y = tf.reduce_mean(x2)\n",
        "\n",
        "tape.gradient(y, x2)"
      ],
      "metadata": {
        "id": "aKWM-aYXggLa",
        "outputId": "d6833042-f27e-443a-c56f-6a6720e19fa6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              "array([[0.25, 0.25],\n",
              "       [0.25, 0.25]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "Hd199nETg5Ph"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3YVfP3R-tp7"
      },
      "source": [
        "### 3. Took gradients through an integer or string\n",
        "\n",
        "Integers and strings are not differentiable. If a calculation path uses these data types there will be no gradient.\n",
        "\n",
        "Nobody expects strings to be differentiable, but it's easy to accidentally create an `int` constant or variable if you don't specify the `dtype`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jlHXHqfASU3",
        "outputId": "3a69f9fe-8cbe-44d8-a76c-5e620fa3b21f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.int32\n",
            "WARNING:tensorflow:The dtype of the target tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n",
            "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "x = tf.constant(10)\n",
        "\n",
        "with tf.GradientTape() as g:\n",
        "  g.watch(x)\n",
        "  y = x * x\n",
        "\n",
        "print(g.gradient(y, x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsdP_mTHX9L1"
      },
      "source": [
        "TensorFlow doesn't automatically cast between types, so, in practice, you'll often get a type error instead of a missing gradient."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyAZ7C8qCEs6"
      },
      "source": [
        "### 4. Took gradients through a stateful object\n",
        "\n",
        "State stops gradients. When you read from a stateful object, the tape can only observe the current state, not the history that lead to it.\n",
        "\n",
        "A `tf.Tensor` is immutable. You can't change a tensor once it's created. It has a _value_, but no _state_. All the operations discussed so far are also stateless: the output of a `tf.matmul` only depends on its inputs.\n",
        "\n",
        "A `tf.Variable` has internal state—its value. When you use the variable, the state is read. It's normal to calculate a gradient with respect to a variable, but the variable's state blocks gradient calculations from going farther back. For example:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1tLeeRFE479",
        "outputId": "9fe867ba-5577-467a-b406-6a137515f235",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "x0 = tf.Variable(3.0)\n",
        "x1 = tf.Variable(0.0)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  # Update x1 = x1 + x0.\n",
        "  x1.assign_add(x0)\n",
        "  # The tape starts recording from x1.\n",
        "  y = x1**2   # y = (x1 + x0)**2\n",
        "\n",
        "# This doesn't work.\n",
        "print(tape.gradient(y, x0))   #dy/dx0 = 2*(x1 + x0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### exploration\n",
        "---\n",
        "---\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "SSbeLKkFk64S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i1 = tf.Variable(1.0)\n",
        "i2 = tf.Variable(2.0)\n",
        "\n",
        "i1 + i2"
      ],
      "metadata": {
        "id": "QDeEd9-jkaaE",
        "outputId": "72e455ca-2b4f-47bb-cb78-772703553e58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=3.0>"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i2.assign_add(i1)"
      ],
      "metadata": {
        "id": "Lv6t-oPikjWr",
        "outputId": "4f451ee7-55ea-4417-c8a8-2244ee048b40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=3.0>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i2"
      ],
      "metadata": {
        "id": "A3gxP2dwkmgb",
        "outputId": "c214cc26-0385-4cc7-fcc1-3488a276a7b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=3.0>"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "JoZBfLVBk_na"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKA92-dqF2r-"
      },
      "source": [
        "Similarly, `tf.data.Dataset` iterators and `tf.queue`s are stateful, and will stop all gradients on tensors that pass through them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHvcDGIbOj2I"
      },
      "source": [
        "## No gradient registered"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoc-A6AxVqry"
      },
      "source": [
        "Some `tf.Operation`s are **registered as being non-differentiable** and will return `None`. Others have **no gradient registered**.\n",
        "\n",
        "The `tf.raw_ops` page shows which low-level ops have gradients registered.\n",
        "\n",
        "If you attempt to take a gradient through a float op that has no gradient registered the tape will throw an error instead of silently returning `None`. This way you know something has gone wrong.\n",
        "\n",
        "For example, the `tf.image.adjust_contrast` function wraps `raw_ops.AdjustContrastv2`, which could have a gradient but the gradient is not implemented:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSb20FXc_V0U",
        "outputId": "96951de7-5049-415f-ce9f-75e11f6cb279",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LookupError: gradient registry has no entry for: AdjustContrastv2\n"
          ]
        }
      ],
      "source": [
        "image = tf.Variable([[[0.5, 0.0, 0.0]]])\n",
        "delta = tf.Variable(0.1)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  new_image = tf.image.adjust_contrast(image, delta)\n",
        "\n",
        "try:\n",
        "  print(tape.gradient(new_image, [image, delta]))\n",
        "  assert False   # This should not happen.\n",
        "except LookupError as e:\n",
        "  print(f'{type(e).__name__}: {e}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDoutjzATiEm"
      },
      "source": [
        "If you need to differentiate through this op, you'll either need to implement the gradient and register it (using `tf.RegisterGradient`) or re-implement the function using other ops."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCTwc_dQXp2W"
      },
      "source": [
        "## Zeros instead of None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYDrVogA89eA"
      },
      "source": [
        "In some cases it would be convenient to get 0 instead of `None` for unconnected gradients.  You can decide what to return when you have unconnected gradients using the `unconnected_gradients` argument:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6zxk1sf9Ixx",
        "outputId": "bb819269-7b95-40aa-eafc-2bdeed249088",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0. 0.], shape=(2,), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "x = tf.Variable([2., 2.])\n",
        "y = tf.Variable(3.)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  z = y**2\n",
        "print(tape.gradient(z, x, unconnected_gradients=tf.UnconnectedGradients.ZERO))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### exploration\n",
        "---\n",
        "---\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "KDz61qyHm7yQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.UnconnectedGradients.ZERO"
      ],
      "metadata": {
        "id": "US19me23muDR",
        "outputId": "92aa6abf-fae8-4c31-8b0e-82ed710478e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<UnconnectedGradients.ZERO: 'zero'>"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.UnconnectedGradients"
      ],
      "metadata": {
        "id": "e-e3QUu2mzHY",
        "outputId": "7cae3660-c093-4fbf-8fc4-e96d6cc522d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<enum 'UnconnectedGradients'>"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir(tf.UnconnectedGradients)"
      ],
      "metadata": {
        "id": "z6z8P2aAm1K4",
        "outputId": "e26ef0de-4294-4330-846e-4833b9f9e15d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NONE', 'ZERO', '__class__', '__doc__', '__members__', '__module__']"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "xgPnCDBsm3xw"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Tce3stUlHN0L"
      ],
      "name": "guide_03_autodiff.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}